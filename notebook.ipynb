{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og0T1ieVf-lO"
      },
      "source": [
        "<CENTER>\n",
        "</br>\n",
        "<p><font size=\"5\">  M2MO - Machine Learning in Finance </font></p>\n",
        "<p><font size=\"5\">  Project - The Deep Parametric PDE Method </font></p>\n",
        "<p><font size=\"4\">  MICHAL Tangui & PÉCHEUL Ronan & SANGLIER Nathan </font></p>\n",
        "<p><font size=\"3\"></br>April 2025</font></br></div>\n",
        "<p><span style=\"color:blue\">michaltangui@gmail.com, ronan.pecheul@ensae.fr, nathan.sanglier@etu.u-paris.fr</span>\n",
        "</p>\n",
        "</CENTER>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook contains a simple implementation of the Deep Parametric PDE method for the case study of pricing a basket put option in the multivariate Black-Scholes model, as described in the report. Our code is inspired by the [Github repository](https://colab.research.google.com/github/LWunderlich/DeepPDE/blob/main/TwoAssetsExample/DeepParametricPDEExample.ipynb) associated to the paper \"<i>The deep parametric PDE method and applications to option pricing</i>\" of K. Glau and L. Wunderlich."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [0 - Imports & Parameters](#section-0)\n",
        "- [I - Neural Network Definition & Training](#section-1)\n",
        "- [II - Numerical Results](#section-2)\n",
        "   - [1 - Error at fixed evaluation point](#section-2-1)\n",
        "   - [2 -  Error for randomly sampled points](#section-2-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span id=\"section-0\" style=\"color:#00B8DE\"> 0 - Imports & Parameters </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np2h-iBVlyIh"
      },
      "outputs": [],
      "source": [
        "import  time\n",
        "import  numpy                       as      np\n",
        "import  matplotlib.pyplot           as      plt\n",
        "import  tensorflow                  as      tf\n",
        "import  tensorflow.keras.backend    as      KB\n",
        "from    tensorflow                  import  keras\n",
        "from    keras.saving                import register_keras_serializable\n",
        "from    scipy.stats                 import  norm\n",
        "from    numpy.polynomial.hermite    import  hermgauss\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_ScUmwViffp"
      },
      "outputs": [],
      "source": [
        "load_model = True # loading existing model (see models folder) or not\n",
        "save_model = False # save the model or not (if load_model = False)\n",
        "\n",
        "s_min_dom, s_max_dom = 25, 150 # asset price domain of interest (different from training domain)\n",
        "t_min_dom, t_max_dom = 0.5, 4. # time domain of interest (different from training domain)\n",
        "\n",
        "rf_eval, vol1_eval, vol2_eval, corr_eval = 0.2, 0.1, 0.3, 0.5 # risk-free rate, volatilities and correlation for option price surface plot\n",
        "\n",
        "n_points_surface_plot   = 21    # nb points in each direction for the surface plot (varying asset prices) of option price\n",
        "n_samples_scatter_plot  = 1000  # nb random points of dataset for the error scatterplots\n",
        "n_samples_oos_error     = 10000 # nb random points for approx L2 and Linf errors\n",
        "\n",
        "########################################### Any change in these paramaters implies to train again the model ###########################################\n",
        "\n",
        "K           = 100.      # strike price\n",
        "opt_type    = 'call'    # 'put' or 'call'\n",
        "gamma       = 1/10.     # lambda in no-arbitrage bound\n",
        "\n",
        "dim_state   = 2 # nb of assets\n",
        "dim_param   = 4 # nb of params (risk-free rate, volatilities, correlation) = 2 * dimension_state\n",
        "dim_tot     = 1 + dim_state + dim_param # nb of dimensions in the input space (time, asset prices, params)\n",
        "\n",
        "rf_min, rf_max      = 0.1, 0.3                  # risk-free rate training domain\n",
        "vol_min, vol_max    = 0.1, 0.3                  # volatilities training domain\n",
        "corr_min, corr_max  = 0.2, 0.8                  # correlation training domain\n",
        "t_min, t_max        = 0., t_max_dom             # time training domain\n",
        "s_max               = K*(1 + 3*vol_max*t_max)   # upper bound asset price training domain\n",
        "x_max               = np.log(s_max)             # upper bound log asset price training domain\n",
        "x_min               = 2*np.log(K)-x_max         # lower bound log asset price training domain\n",
        "\n",
        "norm_max            = 1     # max value of the normalized features space (for the neural net)\n",
        "norm_min            = -1    # min value of the normalized features space (for the neural net)\n",
        "\n",
        "nb_neurons  = 90        # number of nodes per layer\n",
        "init_lr     = 0.001     # initial learning rate for Adam optimizer\n",
        "n_train     = 10000     # number of training points\n",
        "nr_epochs   = 601       # number of epochs for training\n",
        "\n",
        "#######################################################################################################################################################\n",
        "\n",
        "def transform_ab_to_cd(x, a, b, c, d): # transform x in [a,b] to [c,d]\n",
        "    return c + (x-a) * (d-c) / (b-a)\n",
        "\n",
        "diff_dx = (norm_max-norm_min)/(x_max-x_min) # for rescaling gradient wrt x\n",
        "diff_dt = (norm_max-norm_min)/(t_max-t_min) # for rescaling gradient wrt t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span id=\"section-1\" style=\"color:#00B8DE\"> I - Neural Network Definition & Training </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02ogo2SUgO0z"
      },
      "outputs": [],
      "source": [
        "class HighwayLayer(keras.layers.Layer):\n",
        "    \"\"\" Define one layer of the highway network. \"\"\"\n",
        "\n",
        "    def __init__(self, units=50, original_input=dim_tot):\n",
        "        \"\"\" Construct the layer by creating all weights and biases in keras. \"\"\"\n",
        "        super(HighwayLayer, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "        # create all weights and biases\n",
        "        self.Uz = self.add_weight(name=\"Uz\", shape=(original_input, self.units), initializer=\"random_normal\", trainable=True)\n",
        "        self.Ug = self.add_weight(name=\"Ug\", shape=(original_input, self.units), initializer=\"random_normal\", trainable=True)\n",
        "        self.Ur = self.add_weight(name=\"Ur\", shape=(original_input, self.units), initializer=\"random_normal\", trainable=True)\n",
        "        self.Uh = self.add_weight(name=\"Uh\", shape=(original_input, self.units), initializer=\"random_normal\", trainable=True)\n",
        "\n",
        "        self.Wz = self.add_weight(name=\"Wz\", shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
        "        self.Wg = self.add_weight(name=\"Wg\", shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
        "        self.Wr = self.add_weight(name=\"Wr\", shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
        "        self.Wh = self.add_weight(name=\"Wh\", shape=(self.units, self.units), initializer=\"random_normal\", trainable=True)\n",
        "\n",
        "        self.bz = self.add_weight(name=\"bz\", shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
        "        self.bg = self.add_weight(name=\"bg\", shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
        "        self.br = self.add_weight(name=\"br\", shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
        "        self.bh = self.add_weight(name=\"bh\", shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
        "\n",
        "    def call(self, input_combined):\n",
        "        \"\"\" Returns the result of the layer calculation.\"\"\"\n",
        "        previous_layer      = input_combined['previous_layer']\n",
        "        original_variable   = input_combined['original_variable']\n",
        "\n",
        "        # Evaluate one layer using the weights created by the constructor\n",
        "        Z   = tf.keras.activations.tanh(tf.matmul(original_variable, self.Uz) + tf.matmul(previous_layer,self.Wz) + self.bz)\n",
        "        G   = tf.keras.activations.tanh(tf.matmul(original_variable, self.Ug) + tf.matmul(previous_layer,self.Wg) + self.bg)\n",
        "        R   = tf.keras.activations.tanh(tf.matmul(original_variable, self.Ur) + tf.matmul(previous_layer,self.Wr) + self.br)\n",
        "        SR  = tf.multiply(previous_layer, R)\n",
        "        H   = tf.keras.activations.tanh(tf.matmul(original_variable, self.Uh) + tf.matmul(SR, self.Wh) + self.bh)\n",
        "\n",
        "        return tf.multiply(tf.ones_like(G)-G, H) + tf.multiply(Z, previous_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ArbitrageBound(keras.layers.Layer):\n",
        "    \"\"\" Define the no-arbitrage bound for a call or put option, such that the model is trained to learn the residual between option price and the bound. \"\"\"\n",
        "    def __init__(self, gamma, K, opt_type, **kwargs):\n",
        "        super(ArbitrageBound, self).__init__(**kwargs)\n",
        "        self.gamma      = gamma\n",
        "        self.K          = K\n",
        "        self.opt_type   = opt_type\n",
        "\n",
        "    def call(self, inputs):\n",
        "        t       = transform_ab_to_cd(inputs[:, 0:1], norm_min, norm_max, t_min, t_max)\n",
        "        x1      = transform_ab_to_cd(inputs[:, 1:2], norm_min, norm_max, x_min, x_max)\n",
        "        x2      = transform_ab_to_cd(inputs[:, 2:3], norm_min, norm_max, x_min, x_max)\n",
        "        rf      = transform_ab_to_cd(inputs[:, 3:4], norm_min, norm_max, rf_min, rf_max)\n",
        "        s_mean  = (tf.math.exp(x1) + tf.math.exp(x2))/2.0\n",
        "\n",
        "        if self.opt_type == 'call':\n",
        "            bound = tf.math.log(1+tf.math.exp(self.gamma*(s_mean-self.K*tf.exp(-rf*t)))) / self.gamma\n",
        "        elif self.opt_type == 'put':\n",
        "            bound = tf.math.log(1+tf.math.exp(self.gamma*(self.K*tf.exp(-rf*t)-s_mean))) / self.gamma\n",
        "        else:\n",
        "            raise ValueError(\"opt_type must be either 'call' or 'put'.\")\n",
        "        \n",
        "        return bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_network(inputs):\n",
        "    \"\"\" Create the information flow of the model \"\"\"\n",
        "    layer0 = keras.layers.Dense(nb_neurons, activation=\"tanh\")\n",
        "    layer1 = HighwayLayer(units=nb_neurons, original_input=dim_tot)\n",
        "    layer2 = HighwayLayer(units=nb_neurons, original_input=dim_tot)\n",
        "    layer3 = HighwayLayer(units=nb_neurons, original_input=dim_tot)\n",
        "    layer4 = keras.layers.Dense(1)\n",
        "\n",
        "    outputs0 = layer0(inputs)\n",
        "    outputs1 = layer1({'previous_layer': outputs0, 'original_variable': inputs})\n",
        "    outputs2 = layer2({'previous_layer': outputs1, 'original_variable': inputs})\n",
        "    outputs3 = layer3({'previous_layer': outputs2, 'original_variable': inputs})\n",
        "    outputs = layer4(outputs3)\n",
        "\n",
        "    bound           = ArbitrageBound(gamma, K, opt_type)  \n",
        "    bound_outputs   = bound(inputs)\n",
        "    res             = bound_outputs + outputs\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXW4Q0C4bXUj"
      },
      "outputs": [],
      "source": [
        "class DPDEGenerator(keras.utils.Sequence):\n",
        "    \"\"\" Create batches of random points for the network training. \"\"\"\n",
        "    def __init__(self, batch_size):\n",
        "        \"\"\" Initialise the generator by saving the batch size. \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Describes the number of points to create \"\"\"\n",
        "        return self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" Get one batch of random points in the interior of the domain to train the PDE residual and with initial time to train the initial value.\"\"\"\n",
        "        time_train_init         = norm_min * np.ones((self.batch_size, 1), dtype=np.float32)\n",
        "        state_params_train_init = np.random.uniform(norm_min, norm_max, [self.batch_size, dim_state+dim_param]).astype(np.float32)\n",
        "        data_train_initial      = np.concatenate((time_train_init, state_params_train_init), axis=1)\n",
        "        data_train_interior     = np.random.uniform(norm_min, norm_max, [self.batch_size, dim_tot]).astype(np.float32)\n",
        "\n",
        "        return [data_train_interior, data_train_initial]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA1RKeotkzoY"
      },
      "outputs": [],
      "source": [
        "@register_keras_serializable()\n",
        "class DPDEModel(keras.Model):\n",
        "    \"\"\" Create a keras model with the deep param. PDE loss function \"\"\"\n",
        "    def __init__(self, opt_type, **kwargs):\n",
        "        super(DPDEModel, self).__init__(**kwargs)\n",
        "        self.opt_type = opt_type\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"opt_type\": self.opt_type,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        opt_type = config.pop(\"opt_type\")\n",
        "        return cls(opt_type=opt_type, **config)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        \"\"\" Create one optimisation step based on the deep param. PDE loss function. \"\"\"\n",
        "        data_interior, data_init = data\n",
        "\n",
        "        rf_interior     = transform_ab_to_cd(data_interior[:, 3:4], norm_min, norm_max, rf_min, rf_max)\n",
        "        vol1_interior   = transform_ab_to_cd(data_interior[:, 4:5], norm_min, norm_max, vol_min, vol_max)\n",
        "        vol2_interior   = transform_ab_to_cd(data_interior[:, 5:6], norm_min, norm_max, vol_min, vol_max)\n",
        "        corr_interior   = transform_ab_to_cd(data_interior[:, 6:7], norm_min, norm_max, corr_min, corr_max)\n",
        "\n",
        "        x1_init = transform_ab_to_cd(data_init[:, 1:2], norm_min, norm_max, x_min, x_max)\n",
        "        x2_init = transform_ab_to_cd(data_init[:, 2:3], norm_min, norm_max, x_min, x_max)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            v_interior  = self(data_interior, training=True) # Forward pass interior\n",
        "            v_init      = self(data_init, training=True)     # Forward pass initial\n",
        "\n",
        "            grad        = KB.gradients(v_interior, data_interior)[0]\n",
        "            v_dt        = diff_dt * grad[:, 0:1]\n",
        "            v_dx1       = diff_dx * grad[:, 1:2]\n",
        "            v_dx2       = diff_dx * grad[:, 2:3]\n",
        "\n",
        "            grad_v_dx1  = KB.gradients(v_dx1, data_interior)[0]\n",
        "            grad_v_dx2  = KB.gradients(v_dx2, data_interior)[0]\n",
        "            v_dx1dx1    = diff_dx * grad_v_dx1[:, 1:2]\n",
        "            v_dx2dx2    = diff_dx * grad_v_dx2[:, 2:3]\n",
        "            v_dx1dx2    = diff_dx * grad_v_dx1[:, 2:3]\n",
        "            v_dx2dx1    = diff_dx * grad_v_dx2[:, 1:2]\n",
        "\n",
        "            residual_interior = (\n",
        "                v_dt + rf_interior * v_interior\n",
        "                - (rf_interior-vol1_interior**2/2)*v_dx1 - (rf_interior-vol2_interior**2/2)*v_dx2\n",
        "                - 0.5 * vol1_interior**2 * v_dx1dx1 - 0.5 * vol2_interior**2 * v_dx2dx2\n",
        "                - 0.5 * corr_interior * vol1_interior * vol2_interior * v_dx1dx2 - 0.5 * corr_interior * vol2_interior * vol1_interior * v_dx2dx1\n",
        "            ) # should be equal to 0 if the PDE is strictly satisfied\n",
        "\n",
        "            s_mean_init     = 0.5*(tf.math.exp(x1_init)+tf.math.exp(x2_init))\n",
        "            if self.opt_type == 'call':\n",
        "                payoff_init     = KB.maximum(s_mean_init-K, 0)\n",
        "            elif self.opt_type == 'put':\n",
        "                payoff_init     = KB.maximum(K-s_mean_init, 0)\n",
        "            else:\n",
        "                raise ValueError(\"opt_type must be either 'call' or 'put'.\")\n",
        "\n",
        "            # compute loss as squared PDE residuals on interior points and initial points\n",
        "            loss_interior   = KB.mean(KB.square(residual_interior))\n",
        "            loss_init       = KB.mean(KB.square(v_init - payoff_init))\n",
        "            loss            = loss_init + loss_interior\n",
        "\n",
        "        # Compute gradient of loss and update weights\n",
        "        trainable_vars  = self.trainable_variables\n",
        "        gradients       = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        return {\"loss\": loss, \"loss init\": loss_init, \"loss interior\": loss_interior}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "YrLqKY8chkRk",
        "outputId": "5ca37b30-cbc2-4e76-8cb3-54176bc35779"
      },
      "outputs": [],
      "source": [
        "inputs  = keras.Input(shape=(dim_tot,))\n",
        "outputs = create_network(inputs)\n",
        "model   = DPDEModel(inputs=inputs, outputs=outputs, opt_type=opt_type)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(init_lr))\n",
        "\n",
        "if load_model:\n",
        "    # Load model from file.\n",
        "    model.load_weights(f'models/model_{opt_type}.weights.h5')\n",
        "else:\n",
        "    # Create model from scratch.\n",
        "    start           = time.time()\n",
        "    batch_generator = DPDEGenerator(n_train)\n",
        "    callback = tf.keras.callbacks.EarlyStopping('loss', patience=50, restore_best_weights=True) # stop training if loss does not improve for 50 epochs\n",
        "    model.fit(x=batch_generator, epochs=nr_epochs, steps_per_epoch=10, callbacks=[callback])\n",
        "    end             = time.time()\n",
        "    print(f\"Training time: {end-start:.2f} seconds\")\n",
        "    if save_model: model.save_weights(f'models/model_{opt_type}.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span id=\"section-2\" style=\"color:#00B8DE\"> II - Numerical Results </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to evaluate the performance of our Deep Parametric PDE method, we will compare its solution with a reference pricer solution (called \"exact solution\" by abuse of language) known to be highly accurate on this specific basket call or put option pricing problem in the multivariate Black-Scholes model. This reference pricer computes a 1D integral of a smoothed payoff based on \"<i>Smoothing the payoff for efficient computation of basket option prices</i>\" of C. Bayer, M. Siebenmorgen, and R. Tempone, as well as \"<i>Function approximation for option pricing and risk management</i>\" of C. Pötz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCA6YEk8l0Nt"
      },
      "outputs": [],
      "source": [
        "def decompose_covmat(t, vol1, vol2, corr):\n",
        "    \"\"\" Decompose covariance matrix as in Lemma 3.1 of Bayer et. al (2018). \"\"\"\n",
        "    sigma_det = (1-corr**2) * vol1**2 * vol2**2\n",
        "    sigma_sum = (vol1**2 + vol2**2 - 2*corr*vol1*vol2)\n",
        "\n",
        "    ev1     = vol1**2 - corr*vol1*vol2\n",
        "    ev2     = -(vol2**2 - corr*vol1*vol2)\n",
        "    ev_norm = np.sqrt(ev1**2 + ev2**2)\n",
        "\n",
        "    eigval = vol1**2 + vol2**2 - 2*sigma_det/sigma_sum\n",
        "\n",
        "    v_mat   = np.array([ev1, ev2]) / ev_norm\n",
        "    d       = t * np.array([sigma_det/sigma_sum, eigval])\n",
        "    return d, v_mat\n",
        "\n",
        "def bs_formula(t, s, rf, vol, strike, opt_type):\n",
        "\n",
        "    d1 = (1/(vol*np.sqrt(t))) * (np.log(s/strike) + (rf+vol**2/2.)*t)\n",
        "    d2 = d1 - vol*np.sqrt(t)\n",
        "    if opt_type == 'call':\n",
        "        return (norm.cdf(d1)*s - norm.cdf(d2)*strike*np.exp(-rf*t))\n",
        "    elif opt_type == 'put':\n",
        "        return (norm.cdf(-d2)*strike*np.exp(-rf*t) - norm.cdf(-d1)*s)\n",
        "    else:\n",
        "        raise ValueError(\"opt_type must be either 'call' or 'put'.\")\n",
        "\n",
        "def exact_solution(t, s1, s2, rf, vol1, vol2, corr, opt_type):\n",
        "    \"\"\" Compute the option price of a European basket call option. with reference pricer \"\"\"\n",
        "    if t == 0:\n",
        "        if opt_type == 'call':\n",
        "            return np.maximum(0.5*(s1+s2) - K, 0)\n",
        "        elif opt_type == 'put':\n",
        "            return np.maximum(K - 0.5*(s1+s2), 0)\n",
        "        else:\n",
        "            raise ValueError(\"opt_type must be either 'call' or 'put'.\")\n",
        "\n",
        "    d, v = decompose_covmat(t, vol1, vol2, corr)\n",
        "    beta = [0.5*s1*np.exp(-0.5*t*vol1**2), 0.5*s2*np.exp(-0.5*t*vol2**2)]\n",
        "    \n",
        "    integral_points, integral_weights = hermgauss(33)\n",
        "    integral_points  = np.sqrt(2*d[1]) * integral_points.reshape(-1, 1)\n",
        "    integral_weights = integral_weights.reshape(1, -1) / np.sqrt(np.pi)\n",
        "\n",
        "    h_z = (beta[0]*np.exp(v[0]*integral_points) + beta[1]*np.exp(v[1]*integral_points))\n",
        "    eval_integral_points = bs_formula(1, h_z*np.exp(0.5*d[0]), 0., np.sqrt(d[0]), np.exp(-rf*t)*K, opt_type)\n",
        "    sol = np.matmul(integral_weights, eval_integral_points)\n",
        "\n",
        "    return sol[0, 0]\n",
        "\n",
        "# Test for validating the proper functioning of the reference pricer \n",
        "test_solution = exact_solution(4., 100., 100., 0.2, 0.1, 0.3, 0.5, 'call')\n",
        "assert(np.abs(test_solution - 55.096796282039364) < 1e-10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQl6B5M2mKEX"
      },
      "outputs": [],
      "source": [
        "def arbitrage_bound(t, s1, s2, rf, gamma, opt_type):\n",
        "    if opt_type == 'call':\n",
        "        return 1/gamma * np.log(1 + np.exp(gamma*(0.5*(s1+s2) - K*np.exp(-rf*t))))\n",
        "    elif opt_type == 'put':\n",
        "        return 1/gamma * np.log(1 + np.exp(gamma*(K*np.exp(-rf*t) - 0.5*(s1+s2))))\n",
        "    else:\n",
        "        raise ValueError(\"opt_type must be either 'call' or 'put'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span id=\"section-2-1\" style=\"color:#00B8DE\"> II.1 - Error at fixed evaluation point </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first evaluate the solution of our deep paramtric method on a fixed point of paramter space, but for different values of $s_1$ and $s_2$ to get a surface plot of option price based on underlying assets price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpxzRe1fkNbQ"
      },
      "outputs": [],
      "source": [
        "def get_points_plot_fixtime(t, s_min_dom, s_max_dom, rf, vol1, vol2, corr, n_plot):\n",
        "    \"\"\" Get the spatial and normalised values for surface plots at fixed time and parameter, varying both asset prices.\"\"\"\n",
        "    s1_plot = np.linspace(s_min_dom, s_max_dom, n_plot).reshape(-1,1)\n",
        "    s2_plot = np.linspace(s_min_dom, s_max_dom, n_plot).reshape(-1,1)\n",
        "    [s1_plot_mesh, s2_plot_mesh] = np.meshgrid(s1_plot, s2_plot, indexing='ij')\n",
        "\n",
        "    x1_plot_mesh_norm   = transform_ab_to_cd(np.log(s1_plot_mesh), x_min, x_max, norm_min, norm_max).reshape(-1,1)\n",
        "    x2_plot_mesh_norm   = transform_ab_to_cd(np.log(s2_plot_mesh), x_min, x_max, norm_min, norm_max).reshape(-1,1)\n",
        "    t_mesh_norm         = transform_ab_to_cd(t, t_min, t_max, norm_min, norm_max) * np.ones((n_plot**2, 1))\n",
        "    rf_mesh_norm        = transform_ab_to_cd(rf, rf_min, rf_max, norm_min, norm_max) * np.ones((n_plot**2, 1))\n",
        "    vol1_mesh_norm      = transform_ab_to_cd(vol1, vol_min, vol_max, norm_min, norm_max) * np.ones((n_plot**2, 1))\n",
        "    vol2_mesh_norm      = transform_ab_to_cd(vol2, vol_min, vol_max, norm_min, norm_max) * np.ones((n_plot**2, 1))\n",
        "    corr_mesh_norm      = transform_ab_to_cd(corr, corr_min, corr_max, norm_min, norm_max) * np.ones((n_plot**2, 1))\n",
        "\n",
        "    x_plot_norm = np.concatenate((t_mesh_norm, x1_plot_mesh_norm, x2_plot_mesh_norm, rf_mesh_norm, vol1_mesh_norm, vol2_mesh_norm, corr_mesh_norm), axis=1)\n",
        "\n",
        "    return s1_plot_mesh, s2_plot_mesh, x_plot_norm\n",
        "\n",
        "s1_plot_mesh, s2_plot_mesh, x_plot_norm = get_points_plot_fixtime(t_max_dom, s_min_dom, s_max_dom, rf_eval, vol1_eval, vol2_eval, corr_eval, n_points_surface_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dgqVEelxhttp",
        "outputId": "037afdcb-b4fc-44fa-e07b-d599d2fb809a"
      },
      "outputs": [],
      "source": [
        "dpde_sol        = model.predict(x_plot_norm).reshape(n_points_surface_plot, n_points_surface_plot)\n",
        "exact_sol_eval  = [exact_solution(t_max_dom, s1[0], s2[0], rf_eval, vol1_eval, vol2_eval, corr_eval, opt_type) for s1, s2 in zip(s1_plot_mesh.reshape(-1, 1), s2_plot_mesh.reshape(-1, 1))]\n",
        "exact_sol_eval  = np.array(exact_sol_eval)\n",
        "exact_sol_eval  = exact_sol_eval.reshape(n_points_surface_plot, n_points_surface_plot)\n",
        "bound           = arbitrage_bound(t_max_dom, s1_plot_mesh, s2_plot_mesh, rf_eval, gamma, opt_type)\n",
        "err             = np.abs(dpde_sol - exact_sol_eval)\n",
        "residual_hat    = dpde_sol - bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 3, figsize=(18, 6), subplot_kw={'projection': '3d'})\n",
        "\n",
        "axs[0, 0].plot_surface(s1_plot_mesh, s2_plot_mesh, dpde_sol, cmap='viridis')\n",
        "axs[0, 0].set_title('DPDE solution')\n",
        "axs[0, 0].set_xlabel('s1')\n",
        "axs[0, 0].set_ylabel('s2')\n",
        "axs[0, 0].set_zlabel('price')\n",
        "\n",
        "axs[0, 1].plot_surface(s1_plot_mesh, s2_plot_mesh, exact_sol_eval, cmap='viridis')\n",
        "axs[0, 1].set_title('Exact solution')\n",
        "axs[0, 1].set_xlabel('s1')\n",
        "axs[0, 1].set_ylabel('s2')\n",
        "axs[0, 1].set_zlabel('price')\n",
        "\n",
        "axs[0, 2].plot_surface(s1_plot_mesh, s2_plot_mesh, err, cmap='viridis')\n",
        "axs[0, 2].set_title('Absolute error')\n",
        "axs[0, 2].set_xlabel('s1')\n",
        "axs[0, 2].set_ylabel('s2')\n",
        "axs[0, 2].set_zlabel('error')\n",
        "\n",
        "axs[1, 0].plot_surface(s1_plot_mesh, s2_plot_mesh, bound, cmap='viridis')\n",
        "axs[1, 0].set_title('Arbitrage bound')\n",
        "axs[1, 0].set_xlabel('s1')\n",
        "axs[1, 0].set_ylabel('s2')\n",
        "axs[1, 0].set_zlabel('price')\n",
        "\n",
        "\n",
        "axs[1, 1].plot_surface(s1_plot_mesh, s2_plot_mesh, dpde_sol - bound, cmap='viridis')\n",
        "axs[1, 1].set_title('Estimated residual')\n",
        "axs[1, 1].set_xlabel('s1')\n",
        "axs[1, 1].set_ylabel('s2')\n",
        "axs[1, 1].set_zlabel('price')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span id=\"section-2-2\" style=\"color:#00B8DE\"> II.2 - Error for randomly sampled points </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we display the option prices for randomly sampled points in the parameter space for our Deep Parametric PDE method and the reference pricer (no fixed parameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_rd_points_dom(n_samples, t_min_dom, t_max_dom, s_min_dom, s_max_dom, param_min_norm, param_max_norm):\n",
        "    \"\"\" Get a number of random points within the defined domain of interest. \"\"\"\n",
        "    t_sample            = np.random.uniform(t_min_dom, t_max_dom, [n_samples, 1])\n",
        "    t_sample_norm       = transform_ab_to_cd(t_sample, t_min_dom, t_max_dom, norm_min, norm_max)\n",
        "\n",
        "    s_sample        = np.random.uniform(s_min_dom, s_max_dom, [n_samples, dim_state])\n",
        "    s1_sample       = s_sample[:, 0:1]\n",
        "    s2_sample       = s_sample[:, 1:2]\n",
        "    x_sample_norm   = transform_ab_to_cd(np.log(s_sample), x_min, x_max, norm_min, norm_max)\n",
        "\n",
        "    param_sample_norm = np.random.uniform(param_min_norm, param_max_norm, [n_samples, dim_param])\n",
        "    \n",
        "    data_norm = np.concatenate((t_sample_norm, x_sample_norm, param_sample_norm), axis=1)\n",
        "\n",
        "    rf_sample   = transform_ab_to_cd(param_sample_norm[:, 0], norm_min, norm_max, rf_min, rf_max)\n",
        "    vol1_sample = transform_ab_to_cd(param_sample_norm[:, 1], norm_min, norm_max, vol_min, vol_max)\n",
        "    vol2_sample = transform_ab_to_cd(param_sample_norm[:, 2], norm_min, norm_max, vol_min, vol_max)\n",
        "    corr_sample = transform_ab_to_cd(param_sample_norm[:, 3], norm_min, norm_max, corr_min, corr_max)\n",
        "\n",
        "    return data_norm, t_sample.reshape(-1), s1_sample.reshape(-1), s2_sample.reshape(-1), rf_sample, vol1_sample, vol2_sample, corr_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwYnxcCVJx2A"
      },
      "outputs": [],
      "source": [
        "data_norm_sample, t_sample, s1_sample, s2_sample, rf_sample, vol1_sample, vol2_sample, corr_sample = get_rd_points_dom(n_samples_scatter_plot, t_min_dom, t_max_dom, s_min_dom, s_max_dom, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUJBu5_uV6gb"
      },
      "outputs": [],
      "source": [
        "print('Predict {} values and measure the time:'.format(n_samples_scatter_plot))\n",
        "%time dpde_sol = model.predict(data_norm_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfbIGWbSXxis"
      },
      "outputs": [],
      "source": [
        "exact_sol_sample    = [exact_solution(t, s1, s2, rf, vol1, vol2, corr, opt_type) for t, s1, s2, rf, vol1, vol2, corr\n",
        "                        in zip(t_sample, s1_sample, s2_sample, rf_sample, vol1_sample, vol2_sample, corr_sample)]\n",
        "exact_sol_sample    = np.array(exact_sol_sample).reshape(-1,1)\n",
        "err                 = np.abs(dpde_sol - exact_sol_sample)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axs[0].scatter(dpde_sol, exact_sol_sample, s=1)\n",
        "axs[0].set_title('DPDE solution vs. Exact solution')\n",
        "axs[0].set_xlabel('DPDE solution')\n",
        "axs[0].set_ylabel('Exact solution')\n",
        "max_val = max(np.max(dpde_sol), np.max(exact_sol_sample))\n",
        "axs[0].plot([0, max_val], [0, max_val], 'r--', lw=2)\n",
        "\n",
        "\n",
        "axs[1].scatter(dpde_sol, err, s=1)\n",
        "axs[1].set_title('DPDE solution vs. Absolute error')\n",
        "axs[1].set_xlabel('DPDE solution')\n",
        "axs[1].set_ylabel('Absolute error')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let us compute the RMSE of our method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMt40VPLwrpy"
      },
      "outputs": [],
      "source": [
        "data_norm_sample, t_sample, s1_sample, s2_sample, rf_sample, vol1_sample, vol2_sample, corr_sample = get_rd_points_dom(n_samples_oos_error, t_min_dom, t_max_dom, s_min_dom, s_max_dom, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtDOXVmlwxCD"
      },
      "outputs": [],
      "source": [
        "print('Predict {} values and measure the time:'.format(n_samples_scatter_plot))\n",
        "%time dpde_sol = model.predict(data_norm_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf2MVuVTwyvn"
      },
      "outputs": [],
      "source": [
        "exact_sol_sample        = [exact_solution(t, s1, s2, rf, vol1, vol2, corr, opt_type) for t, s1, s2, rf, vol1, vol2, corr\n",
        "                                in zip(t_sample, s1_sample, s2_sample, rf_sample, vol1_sample, vol2_sample, corr_sample)]\n",
        "exact_sol_sample        = np.array(exact_sol_sample).reshape(-1,1)\n",
        "err                     = np.abs(dpde_sol - exact_sol_sample)\n",
        "rmse                    = np.sqrt(np.mean(np.square(err)))\n",
        "\n",
        "print(f'estimated RMSE = {rmse:.2f}')\n",
        "print(f'normalized estimated RMSE = {rmse/np.sqrt(np.mean(np.square(exact_sol_sample))):.2%}')\n",
        "print(f'Maximal absolute error = {np.max(err):.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
